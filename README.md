1. A real-time sign-language detection web app to classify hand gestures as rock, paper, pencil or scissor using opencv, mediapipe and webcam.
2. Utilised mediapipe to extract hand landmarks.
3. The training dataset comprises 500 images for each class.
4. Trained a random forest model to classify the hand gestures.
5. Used a subset of training data as testing data (20%).
6. Achieved an accuracy of 98.95% on test data.
